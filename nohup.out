Traceback (most recent call last):
  File "/mnt/data/user_liangzhiyu/wangzhongzheng/LLM4SSS/LLM4SSSrun.py", line 17, in <module>
    main(sys.argv)
  File "/mnt/data/user_liangzhiyu/wangzhongzheng/LLM4SSS/LLM4SSSrun.py", line 13, in main
    expe.run()
  File "/mnt/data/user_liangzhiyu/wangzhongzheng/LLM4SSS/utils/expe.py", line 52, in run
    self.train()
  File "/mnt/data/user_liangzhiyu/wangzhongzheng/LLM4SSS/utils/expe.py", line 101, in train
    one_batch_reduce = self.model(one_batch)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/data/user_liangzhiyu/wangzhongzheng/LLM4SSS/model/TStransformer.py", line 56, in forward
    x = self.transformer(x, x)  # (len_series, batch_size, embed_size)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 138, in forward
    output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 245, in forward
    output = mod(output, memory, tgt_mask=tgt_mask,
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 408, in forward
    tgt2 = self.multihead_attn(tgt, memory, memory, attn_mask=memory_mask,
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1031, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/functional.py", line 5089, in multi_head_attention_forward
    return attn_output, attn_output_weights.sum(dim=1) / num_heads
RuntimeError: CUDA out of memory. Tried to allocate 58.00 MiB (GPU 6; 23.60 GiB total capacity; 16.01 GiB already allocated; 45.19 MiB free; 16.30 GiB reserved in total by PyTorch)
