Traceback (most recent call last):
  File "/mnt/data/user_liangzhiyu/wangzhongzheng/LLM4SSS/LLM4SSSrun.py", line 17, in <module>
    main(sys.argv)
  File "/mnt/data/user_liangzhiyu/wangzhongzheng/LLM4SSS/LLM4SSSrun.py", line 13, in main
    expe.run()
  File "/mnt/data/user_liangzhiyu/wangzhongzheng/LLM4SSS/utils/expe.py", line 53, in run
    self.train()
  File "/mnt/data/user_liangzhiyu/wangzhongzheng/LLM4SSS/utils/expe.py", line 112, in train
    another_batch_reduce = self.model(another_batch)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/_utils.py", line 425, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in replica 3 on device 7.
Original Traceback (most recent call last):
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/data/user_liangzhiyu/wangzhongzheng/LLM4SSS/model/TStransformer.py", line 56, in forward
    x = self.transformer(x, x)  # (len_series, batch_size, embed_size)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 137, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 195, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 320, in forward
    src2 = self.self_attn(src, src, src, attn_mask=src_mask,
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1031, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/functional.py", line 5082, in multi_head_attention_forward
    attn_output, attn_output_weights = _scaled_dot_product_attention(q, k, v, attn_mask, dropout_p)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/functional.py", line 4828, in _scaled_dot_product_attention
    attn = softmax(attn, dim=-1)
  File "/mnt/data/user_liangzhiyu/envs/wzz/lib/python3.9/site-packages/torch/nn/functional.py", line 1679, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 226.00 MiB (GPU 7; 23.60 GiB total capacity; 16.44 GiB already allocated; 61.19 MiB free; 16.82 GiB reserved in total by PyTorch)

